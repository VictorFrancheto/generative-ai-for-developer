{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“© Building a Spam Classifier with Foundation Models\n",
        "\n",
        "## ðŸš€ Project Overview\n",
        "\n",
        "Foundation models enable a wide range of intelligent applications without requiring task-specific training.  \n",
        "In this project, you will build a **spam classifier using only prompt engineering**, leveraging the modelâ€™s language understanding and reasoning capabilities.\n",
        "\n",
        "The objective is to classify SMS messages as **SPAM** or **NOT SPAM** while enforcing a structured **JSON output**, making the results easy to parse and integrate into downstream applications.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§­ Step-by-Step Workflow\n",
        "\n",
        "### ðŸ§© Step 1 â€” Define the Task and Output Format  \n",
        "- Create a **SYSTEM_PROMPT** that clearly specifies:\n",
        "  - ðŸ¤– The modelâ€™s role  \n",
        "  - ðŸŽ¯ The classification task  \n",
        "  - ðŸ“¦ The required JSON output structure  \n",
        "- This ensures consistent and machine-readable responses.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¬ Step 2 â€” Zero-Shot Classification  \n",
        "- Start with **instructions only**, without examples.  \n",
        "- Evaluate how well the model performs based solely on its prior knowledge.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“˜ Step 3 â€” Few-Shot Enhancement  \n",
        "- Add a small set of **labeled examples** to the prompt.  \n",
        "- Use these in-context demonstrations to improve prediction consistency and accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“± Step 4 â€” Apply to Spam Detection  \n",
        "- Use the prompt structure to classify SMS messages as **SPAM** or **NOT SPAM**.  \n",
        "- Validate the JSON output and analyze prediction quality.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸš€ Step 5 â€” Iterate and Improve  \n",
        "- Refine prompt wording and constraints.  \n",
        "- Experiment with different example selections.  \n",
        "- Compare zero-shot and few-shot performance.  \n",
        "- Identify edge cases and limitations.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Key Takeaways\n",
        "\n",
        "- ðŸ› ï¸ Well-designed prompts can transform foundation models into practical classifiers.  \n",
        "- âš¡ Zero-shot prompting is fast and simple but may lack precision.  \n",
        "- ðŸŽ¯ Few-shot prompting often improves reliability but does not eliminate ambiguity.  \n",
        "- ðŸ” The same prompting pattern can be adapted to many classification tasks beyond spam detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“š Importing libraries and environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Vocareum OpenAI API base URL\n"
          ]
        }
      ],
      "source": [
        "import litellm\n",
        "import os\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\"):\n",
        "    litellm.openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# If using Vocareum, you can also set your API key here directly\n",
        "# Uncomment and replace the string with your actual Vocareum API key\n",
        "\n",
        "if (litellm.openai_key or \"\").startswith(\"voc-\"):\n",
        "    litellm.api_base = \"https://openai.vocareum.com/v1\"\n",
        "    print(\"Using Vocareum OpenAI API base URL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Data Preparation\n",
        "\n",
        "To build and evaluate the spam classifier, you need a dataset of messages labeled as **SPAM** or **NOT SPAM**.  \n",
        "Selecting a representative dataset is essential to capture a diverse range of message patterns, including both legitimate and unwanted content.\n",
        "\n",
        "A well-balanced and well-curated dataset improves the reliability of the evaluation and helps ensure that the classifier generalizes effectively to real-world scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label=0, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "label=0, sms=Ok lar... Joking wif u oni...\n",
            "\n",
            "label=1, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the sms_spam dataset using the datasets library\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
        "\n",
        "for entry in dataset.select(range(3)):\n",
        "    sms = entry[\"sms\"]\n",
        "    label = entry[\"label\"]\n",
        "    print(f\"label={label}, sms={sms}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ·ï¸ Improving Label Readability\n",
        "\n",
        "The numerical labels can be difficult to interpret at a glance.  \n",
        "To make the output more readable and user-friendly, we will create helper functions to convert numeric IDs into meaningful labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label=NOT SPAM, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "label=NOT SPAM, sms=Ok lar... Joking wif u oni...\n",
            "\n",
            "label=SPAM, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n"
          ]
        }
      ],
      "source": [
        "id2label = {0: \"NOT SPAM\", 1: \"SPAM\"}\n",
        "label2id = {\"NOT SPAM\": 0, \"SPAM\": 1}\n",
        "\n",
        "for entry in dataset.select(range(3)):\n",
        "    sms = entry[\"sms\"]\n",
        "    label_id = entry[\"label\"]\n",
        "    print(f\"label={id2label[label_id]}, sms={sms}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¤– Build and Evaluate the Spam Classifier\n",
        "\n",
        "Using the foundation model and the prepared dataset, you will build a spam classifier based entirely on prompting.\n",
        "\n",
        "Create a prompt that asks the model to classify 15 messages as either **\"SPAM\"** or **\"NOT SPAM\"**.  \n",
        "To simplify downstream processing and automatic validation, require the LLM to return the predictions in a structured **JSON format**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\n",
            "1 -> Ok lar... Joking wif u oni...\n",
            "\n",
            "2 -> Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a helper function to get multiple sms messages as a single string\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def get_sms_messages_string(dataset, item_numbers):\n",
        "    sms_messages_string = \"\"\n",
        "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
        "        sms = entry[\"sms\"]\n",
        "        label_id = entry[\"label\"]\n",
        "\n",
        "        sms_messages_string += f\"{item_number} -> {sms}\\n\"\n",
        "\n",
        "    return sms_messages_string\n",
        "\n",
        "\n",
        "print(get_sms_messages_string(dataset, [0, 1, 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§© Prompt Construction\n",
        "\n",
        "Next, write the code that generates the prompt sent to the LLM.  \n",
        "The prompt should include a small set of SMS messages to be classified, along with clear instructions describing the task.\n",
        "\n",
        "Many LLMs can also format their responses automatically when instructed. For example, you can explicitly request: **\"Respond in JSON format.\"** This helps ensure consistent and machine-readable outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SYSTEM PROMPT:\n",
            " You are a text classification assistant.\n",
            "You will receive multiple SMS messages in the format:\n",
            "<id> -> <message>\n",
            "\n",
            "Your task is to classify each message as either \"SPAM\" or \"NOT SPAM\".\n",
            "\n",
            "Return the result strictly in valid JSON format, where:\n",
            "- The keys are the message IDs.\n",
            "- The values are the predicted labels (\"SPAM\" or \"NOT SPAM\").\n",
            "- Do not include any extra text, explanations, or formatting outside the JSON.\n",
            "\n",
            "\n",
            "USER PROMPT:\n",
            "7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
            "\n",
            "8 -> WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
            "\n",
            "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
            "\n",
            "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
            "\n",
            "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
            "\n",
            "12 -> URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
            "\n",
            "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
            "\n",
            "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a few messages and format them as a string\n",
        "sms_messages_string = get_sms_messages_string(dataset, range(7, 15))\n",
        "\n",
        "# The input should be of the form\n",
        "# 11 -> ...\n",
        "# 16 -> ...\n",
        "# 23 -> ...\n",
        "\n",
        "# The output should be of the form\n",
        "# {\n",
        "#     \"11\": \"NOT SPAM\",\n",
        "#     \"16\": \"SPAM\",\n",
        "#     \"23\": \"NOT SPAM\"\n",
        "# }\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\" You are a text classification assistant.\n",
        "You will receive multiple SMS messages in the format:\n",
        "<id> -> <message>\n",
        "\n",
        "Your task is to classify each message as either \"SPAM\" or \"NOT SPAM\".\n",
        "\n",
        "Return the result strictly in valid JSON format, where:\n",
        "- The keys are the message IDs.\n",
        "- The values are the predicted labels (\"SPAM\" or \"NOT SPAM\").\n",
        "- Do not include any extra text, explanations, or formatting outside the JSON.\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT = sms_messages_string\n",
        "\n",
        "\n",
        "print(\"SYSTEM PROMPT:\")\n",
        "print(SYSTEM_PROMPT)\n",
        "print(\"\\nUSER PROMPT:\")\n",
        "print(USER_PROMPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"7\": \"SPAM\",\n",
            "  \"8\": \"SPAM\",\n",
            "  \"9\": \"SPAM\",\n",
            "  \"10\": \"NOT SPAM\",\n",
            "  \"11\": \"SPAM\",\n",
            "  \"12\": \"SPAM\",\n",
            "  \"13\": \"NOT SPAM\",\n",
            "  \"14\": \"NOT SPAM\"\n",
            "}\n",
            "Response is valid JSON\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion\n",
        "\n",
        "response = completion(\n",
        "    model=\"gpt-5-nano\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
        "    ],\n",
        ")\n",
        "response = response.choices[0].message.content\n",
        "print(response)\n",
        "\n",
        "# Check that response is in valid JSON format\n",
        "try:\n",
        "    import json\n",
        "\n",
        "    json.loads(response)\n",
        "    print(\"Response is valid JSON\")\n",
        "except json.JSONDecodeError:\n",
        "    print(\"Response is not valid JSON\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Performance Evaluation\n",
        "\n",
        "To quantitatively assess the quality of the predictions, we implement a function that matches the LLM outputs against the reference labels in the dataset.  \n",
        "The resulting accuracy metric provides a simple measure of classification performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mismatch for entry 7: predicted=SPAM, actual=NOT SPAM\n",
            "Accuracy: 0.88\n"
          ]
        }
      ],
      "source": [
        "def get_accuracy(response, dataset, original_indices):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if isinstance(response, str):\n",
        "        import json\n",
        "\n",
        "        try:\n",
        "            response = json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"Error decoding JSON response:\", e)\n",
        "            return\n",
        "\n",
        "    for entry_number, prediction in response.items():\n",
        "        if int(entry_number) not in original_indices:\n",
        "            continue\n",
        "\n",
        "        label_id = dataset[int(entry_number)][\"label\"]\n",
        "        label = id2label[label_id]\n",
        "\n",
        "        # If the prediction from the LLM matches the label in the dataset\n",
        "        # we increment the number of correct predictions.\n",
        "        # (Since LLMs do not always produce the same output, we use the\n",
        "        # lower case version of the strings for comparison)\n",
        "        if prediction.lower() == label.lower():\n",
        "            correct += 1\n",
        "        else:\n",
        "            print(\n",
        "                f\"Mismatch for entry {entry_number}: predicted={prediction}, actual={label}\"\n",
        "            )\n",
        "\n",
        "        # increment the total number of predictions\n",
        "        total += 1\n",
        "\n",
        "    try:\n",
        "        accuracy = correct / total\n",
        "    except ZeroDivisionError:\n",
        "        print(\"No matching results found!\")\n",
        "        return\n",
        "\n",
        "    return round(accuracy, 2)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's a strong result â€” and even better if all predictions were correct.\n",
        "\n",
        "While the model may not classify every possible example perfectly, this performance is an excellent starting point, especially given that no labeled examples or training data were provided.\n",
        "\n",
        "The results show that the model can reliably distinguish between spam and legitimate messages with a high level of accuracy, illustrating how foundation models can be effectively used to build practical spam classification systems using only prompting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Build an Improved Classifier\n",
        "\n",
        "Providing the LLM with a small set of labeled examples can often improve its performance.  \n",
        "In this step, we apply few-shot prompting to guide the model with concrete examples and evaluate whether this leads to more accurate and consistent classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXAMPLE INPUT:\n",
            "54 -> SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV\n",
            "\n",
            "55 -> Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
            "\n",
            "56 -> Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! \n",
            "\n",
            "57 -> Sorry, I'll call later in meeting.\n",
            "\n",
            "58 -> Tell where you reached\n",
            "\n",
            "59 -> Yes..gauti and sehwag out of odi series.\n",
            "\n",
            "EXAMPLE OUTPUT:\n",
            "{\n",
            "    \"54\": \"SPAM\",\n",
            "    \"55\": \"NOT SPAM\",\n",
            "    \"56\": \"SPAM\",\n",
            "    \"57\": \"NOT SPAM\",\n",
            "    \"58\": \"NOT SPAM\",\n",
            "    \"59\": \"NOT SPAM\",\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_few_shot_examples_string(dataset, item_numbers):\n",
        "    examples_string = \"\"\n",
        "\n",
        "    examples_string += \"EXAMPLE INPUT:\\n\"\n",
        "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
        "        sms = entry[\"sms\"]\n",
        "\n",
        "        examples_string += f\"{item_number} -> {sms}\\n\"\n",
        "\n",
        "    examples_string += \"EXAMPLE OUTPUT:\\n\"\n",
        "    examples_string += \"{\\n\"\n",
        "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
        "        label_id = entry[\"label\"]\n",
        "        label = id2label[label_id]\n",
        "        examples_string += f'    \"{item_number}\": \"{label}\",\\n'\n",
        "    examples_string += \"}\\n\"\n",
        "\n",
        "    return examples_string\n",
        "\n",
        "\n",
        "print(get_few_shot_examples_string(dataset, range(54, 60)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SYSTEM_PROMPT:\n",
            "\n",
            "You are a text classification assistant.\n",
            "\n",
            "You will receive:\n",
            "1) Some labelled SMS examples.\n",
            "2) A list of unlabelled SMS messages.\n",
            "\n",
            "Your task is to classify each unlabelled message as either \"SPAM\" or \"NOT SPAM\".\n",
            "\n",
            "Return the result strictly in valid JSON format:\n",
            "- Keys must be the message IDs.\n",
            "- Values must be \"SPAM\" or \"NOT SPAM\".\n",
            "- Do not include explanations or any text outside the JSON.\n",
            "\n",
            "USER_PROMPT:\n",
            "\n",
            "Here are some labelled examples:\n",
            "\n",
            "EXAMPLE INPUT:\n",
            "54 -> SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV\n",
            "\n",
            "55 -> Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
            "\n",
            "56 -> Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! \n",
            "\n",
            "57 -> Sorry, I'll call later in meeting.\n",
            "\n",
            "58 -> Tell where you reached\n",
            "\n",
            "59 -> Yes..gauti and sehwag out of odi series.\n",
            "\n",
            "EXAMPLE OUTPUT:\n",
            "{\n",
            "    \"54\": \"SPAM\",\n",
            "    \"55\": \"NOT SPAM\",\n",
            "    \"56\": \"SPAM\",\n",
            "    \"57\": \"NOT SPAM\",\n",
            "    \"58\": \"NOT SPAM\",\n",
            "    \"59\": \"NOT SPAM\",\n",
            "}\n",
            "\n",
            "\n",
            "Now classify the following unlabelled messages:\n",
            "\n",
            "7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
            "\n",
            "8 -> WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
            "\n",
            "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
            "\n",
            "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
            "\n",
            "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
            "\n",
            "12 -> URGENT! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
            "\n",
            "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
            "\n",
            "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a few messages and format them as a string\n",
        "sms_messages_string = get_sms_messages_string(dataset, range(7, 15))\n",
        "\n",
        "# Construct a SYSTEM_PROMPT and USER_PROMPT to send to the LLM. This time, let's include the\n",
        "# labelled examples to see if it improves accuracy. Hint: use get_few_shot_examples_string(dataset, range(54, 60))\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a text classification assistant.\n",
        "\n",
        "You will receive:\n",
        "1) Some labelled SMS examples.\n",
        "2) A list of unlabelled SMS messages.\n",
        "\n",
        "Your task is to classify each unlabelled message as either \"SPAM\" or \"NOT SPAM\".\n",
        "\n",
        "Return the result strictly in valid JSON format:\n",
        "- Keys must be the message IDs.\n",
        "- Values must be \"SPAM\" or \"NOT SPAM\".\n",
        "- Do not include explanations or any text outside the JSON.\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT = f\"\"\"\n",
        "Here are some labelled examples:\n",
        "\n",
        "{get_few_shot_examples_string(dataset, range(54, 60))}\n",
        "\n",
        "Now classify the following unlabelled messages:\n",
        "\n",
        "{sms_messages_string}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "print(\"SYSTEM_PROMPT:\")\n",
        "print(SYSTEM_PROMPT)\n",
        "print(\"USER_PROMPT:\")\n",
        "print(USER_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ“¥ Paste in your response from the LLM below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"7\": \"NOT SPAM\",\n",
            "  \"8\": \"SPAM\",\n",
            "  \"9\": \"SPAM\",\n",
            "  \"10\": \"NOT SPAM\",\n",
            "  \"11\": \"SPAM\",\n",
            "  \"12\": \"SPAM\",\n",
            "  \"13\": \"NOT SPAM\",\n",
            "  \"14\": \"NOT SPAM\"\n",
            "}\n",
            "Response is valid JSON\n"
          ]
        }
      ],
      "source": [
        "# Get the response from the LLM\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "response = completion(\n",
        "    model=\"gpt-5-nano\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = response.choices[0].message.content\n",
        "print(response)\n",
        "\n",
        "# Check that response is in valid JSON format\n",
        "try:\n",
        "    import json\n",
        "\n",
        "    json.loads(response)\n",
        "    print(\"Response is valid JSON\")\n",
        "except json.JSONDecodeError:\n",
        "    print(\"Response is not valid JSON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the accuracy now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Estimate the accuracy of your classifier by comparing your responses to the labels in the dataset\n",
        "\n",
        "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15)):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do you still observe any errors in the results? If so, what factors do you believe are contributing to these errors?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
