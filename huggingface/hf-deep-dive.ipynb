{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ICKz3DBsH0M"
      },
      "source": [
        "# ü§ó HuggingFace: A Deep Dive\n",
        "\n",
        "Welcome to the HuggingFace universe! In this journey, we'll explore the main features of this amazing platform for NLP and generative AI. Get ready to learn with practical examples, detailed explanations, and lots of emojis to make everything more fun! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWDIzTSzsH0N"
      },
      "source": [
        "ü§ñ HuggingFace is a technology company that has revolutionized the field of Natural Language Processing (NLP) and Machine Learning. Its main highlight is the open-source Transformers library, which democratized access to state-of-the-art NLP models, making them accessible to researchers, developers, and enthusiasts.\n",
        "\n",
        "### Example use cases for HuggingFace:\n",
        "- **Smart chatbots** (like virtual assistants)\n",
        "- **Sentiment analysis** on social media\n",
        "- **Automatic language translation**\n",
        "- **Creative text generation** (stories, scripts, etc)\n",
        "- **Summarizing long texts** automatically\n",
        "- **Named Entity Recognition** (extracting names, places, etc)\n",
        "- **Question answering** (extracting answers from documents)\n",
        "\n",
        "üí° Let's see how all this works in practice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3bpHASsH0O"
      },
      "source": [
        "## üó∫Ô∏è Roadmap for Our Journey\n",
        "\n",
        "Hugging Face offers several components to make advanced research and practical applications easier. Here, we'll focus on the four essential pillars for NLP tasks:\n",
        "\n",
        "* üß© **Tokenizers**: Transform text into numbers that models can understand. Example: splitting sentences into words or subwords.\n",
        "  - Example: \"I love AI!\" ‚Üí [\"I\", \"love\", \"AI\", \"!\"]\n",
        "  - Another example: \"Transformers are awesome!\" ‚Üí [\"Transform\", \"##ers\", \"are\", \"awesome\", \"!\"]\n",
        "* üß† **Models**: The heart of the platform! Pre-trained models like GPT, BERT, Qwen, and many others, ready for various tasks.\n",
        "  - Example: Generate text, answer questions, translate languages.\n",
        "  - Example: Classify emails as spam or not spam.\n",
        "* üìö **Datasets**: Data is the fuel for machine learning. Hugging Face offers a standardized library to access and process a wide range of datasets.\n",
        "  - Example: Datasets of tweets, news, question-answer pairs, product reviews, etc.\n",
        "* üèãÔ∏è‚Äç‚ôÇÔ∏è **Trainers**: Make model training easier, simplifying and speeding up the process.\n",
        "  - Example: Train a model to classify movie reviews as positive or negative.\n",
        "\n",
        "We'll also explore two amazing Hugging Face libraries for:\n",
        "- üîß **Efficient fine-tuning** (adjusting models with few parameters)\n",
        "- üèÜ **Reinforcement Learning** for transformer development\n",
        "\n",
        "Let's get started! ‚ú®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r-SUM9VsH0O"
      },
      "source": [
        "## üß© Tokenizers\n",
        "\n",
        "Tokenization means breaking down text into smaller units, called tokens, which can be as small as characters or as long as words. Hugging Face offers a dedicated library for tokenization that is both robust and efficient.\n",
        "\n",
        "### Why is tokenization important? ü§î\n",
        "- Models can't understand raw text, only numbers!\n",
        "- Tokenization helps convert text into a format that models can process.\n",
        "\n",
        "### Examples:\n",
        "- \"I love AI!\" ‚Üí [\"I\", \"love\", \"AI\", \"!\"]\n",
        "- \"Transformers are awesome!\" ‚Üí [\"Transform\", \"##ers\", \"are\", \"awesome\", \"!\"]\n",
        "- \"Let's tokenize this sentence.\" ‚Üí [\"Let\", \"'s\", \"token\", \"##ize\", \"this\", \"sentence\", \".\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wg5pgGisH0P",
        "outputId": "7b78f262-46f5-406c-9de8-e927d366be81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of distinct tokens that bert-base-uncased uses is 30522\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "print(f\"The number of distinct tokens that bert-base-uncased uses is {tokenizer.vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mg0lMC4sH0P"
      },
      "source": [
        "Let's see tokenizers in action! Here we load the tokenizer used for a BERT model, specifically a pre-trained model called `bert-base-uncased`. *Uncased* means the model was trained with a tokenizer that does not distinguish between uppercase and lowercase letters.\n",
        "\n",
        "The number of distinct tokens that `bert-base-uncased` uses is 30.522. This includes individual letters, words, and word parts.\n",
        "\n",
        "### More examples:\n",
        "- Try tokenizing: \"HuggingFace makes NLP easy!\"\n",
        "- Try tokenizing: \"2026 is the year of AI.\"\n",
        "\n",
        "Notice how numbers, punctuation, and even unknown words are handled!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['transformers', 'are', 'awesome', '!', '!']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Transformers are awesome!!\"\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZEcv9ZOsH0Q"
      },
      "source": [
        "We will tokenize the sentence \"Transformers are awesome!!\" using the `tokenizer.tokenize` method and print the result. Notice that \"generative\" was split into two tokens.\n",
        "\n",
        "### Try more examples:\n",
        "- \"Deep learning is fun!\"\n",
        "- \"Let's build something amazing.\"\n",
        "\n",
        "See how different words and punctuation are split into tokens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Mun80KsH0Q",
        "outputId": "195ed8e7-f1ce-42ab-b39a-3df98b4e1869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19081, 2024, 12476, 999, 999]\n"
          ]
        }
      ],
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIqYAxDusH0Q"
      },
      "source": [
        "We can also see the actual token values as numbers that the model uses internally, starting with 19081.\n",
        "\n",
        "### Try converting tokens to IDs for other sentences:\n",
        "- \"AI is everywhere!\"\n",
        "- \"HuggingFace rocks!\"\n",
        "\n",
        "Each token has a unique ID in the model's vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_3S0fnZsH0Q"
      },
      "source": [
        "One notable feature of Hugging Face‚Äôs tokenizers is their speed. By leveraging a programming language called Rust under the hood, the library ensures rapid tokenization, even for vast amounts of text.\n",
        "\n",
        "### Fun fact:\n",
        "- You can tokenize entire books or large datasets in seconds!\n",
        "- Try tokenizing a paragraph or a list of sentences and see how fast it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpak6HMxsH0Q"
      },
      "source": [
        "## üß† Models\n",
        "\n",
        "Let's look at accessing the diverse and expansive collection of open-source models available on HuggingFace. You'll find lots of foundation models such as GPT, Qwen, Google's Gemma, and many more. There are also fine-tuned variants made by the community!\n",
        "\n",
        "### What can you do with models?\n",
        "- Text classification (spam detection, sentiment analysis)\n",
        "- Text generation (stories, code, emails)\n",
        "- Translation (English ‚ÜîÔ∏è French, etc)\n",
        "- Question answering\n",
        "- Named entity recognition\n",
        "\n",
        "Let's see how to use a pre-trained model for sentiment analysis! üé¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gRgS1MTIsH0Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71b124830f1846acb7140765fce40f0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victor.francheto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\victor.francheto\\.cache\\huggingface\\hub\\models--textattack--bert-base-uncased-imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9572349f07f4b92961c2264a305b809",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1f105327a744bdc8ae64b0fbb5de8c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f800d1346b904498964a376c7bf94ed6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = 'textattack/bert-base-uncased-imdb'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXcXtMeIsH0Q"
      },
      "source": [
        "Let's download a model from HuggingFace and use it for sentiment analysis!\n",
        "\n",
        "Here's a quick demonstration using a pre-trained model to classify the sentiment of the sentence \"I love Generative AI\". First, we load a model and a tokenizer using a model pre-trained by the community and available on HuggingFace. In this case, we are using the 'textattack/bert-base-uncased-imdb' model, which is adapted for movie review sentiment analysis.\n",
        "\n",
        "### Try more examples:\n",
        "- \"This movie was fantastic!\"\n",
        "- \"I didn't like the ending.\"\n",
        "- \"The actors did a great job.\"\n",
        "\n",
        "See how the model predicts the sentiment for different sentences!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbfOrSdosH0Q",
        "outputId": "84985504-c3a5-4a07-e0dd-1fb64776e1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment is positive with a probability of 0.89\n"
          ]
        }
      ],
      "source": [
        "sentence = \"I love Generative AI\"\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    prediction = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "if prediction == 1:\n",
        "    print(f'The sentiment is positive with a probability of {probabilities[0][1]:.2f}')\n",
        "else:\n",
        "    print(f'The sentiment is negative with a probability of {probabilities[0][0]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPEZhbE-sH0R"
      },
      "source": [
        "To get the prediction, we go through a few steps:\n",
        "\n",
        "1. Tokenize the input using the tokenizer\n",
        "2. Use `no_grad` to tell the model we're only making predictions (not training)\n",
        "3. Get the output probabilities for positive vs negative sentiment\n",
        "4. Print the result with the probability\n",
        "\n",
        "So, \"I love generative AI\" has a positive sentiment according to this model, with a probability of 89% (for example).\n",
        "\n",
        "### Try more sentences and see the probabilities!\n",
        "- \"This is the best product ever!\"\n",
        "- \"I wouldn't recommend this to anyone.\"\n",
        "- \"The plot was confusing but the visuals were stunning.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPUZPacGsH0R"
      },
      "source": [
        "## üìö Datasets\n",
        "\n",
        "Now let's turn to accessing datasets. Hugging Face's \"Datasets\" library is designed to make it fast and easy to access, preprocess, and manage large amounts of data for AI projects.\n",
        "\n",
        "### Why use HuggingFace Datasets?\n",
        "- Access 1000s of public datasets with one line of code\n",
        "- Built-in tools for filtering, mapping, and transforming data\n",
        "- Efficient memory usage, even for huge datasets\n",
        "\n",
        "### Example datasets:\n",
        "- IMDB (movie reviews)\n",
        "- SQuAD (question answering)\n",
        "- AG News (news classification)\n",
        "- Amazon Reviews\n",
        "- Common Crawl (web data)\n",
        "\n",
        "Let's load a dataset and explore it! üîç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CAWHhyousH0R"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2d103403c3445c5816c7b89bb7ba7eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\victor.francheto\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\victor.francheto\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39eb0513c1f3460bb74d6139190d14e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb77dd6c5a9d4965b3cf7b94a60a3b5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b848f52c41492b84ef42d3b09c6d4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(‚Ä¶):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "707f83466bf841139cc0dde44fdcfdce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "033b19a85da34e7c8fbbd9c4a55182b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c756d0dd5a4442ba98ff8eb048d3b1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset('imdb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn6MDfnRsH0R"
      },
      "source": [
        "How easy is it? The `datasets` library provides an efficient way to access a myriad of datasets, including the popular IMDB dataset with movie reviews. In this example, we load the IMDB dataset and display one of its reviews.\n",
        "\n",
        "Try loading other datasets, like 'ag_news' or 'amazon_polarity', and print some samples!\n",
        "\n",
        "### More examples:\n",
        "- Load the 'squad' dataset and print a question-answer pair\n",
        "- Load the 'emotion' dataset and print a labeled sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_fTcCtGsH0R",
        "outputId": "8b06c7c1-45e3-4bae-fb57-6122d994f496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review text: WARNING: This review contains SPOILERS. Do not read if you don't want some points revealed to you before you watch the film.<br /><br />With a cast like this, you wonder whether or not the actors and actresses knew exactly what they were getting into. Did they see the script and say, `Hey, Close Encounters of the Third Kind was such a hit that this one can't fail.' Unfortunately, it does. Did they even think to check on the director's credentials? I mean, would YOU do a movie with the director of a movie called `Satan's Cheerleaders?' Greydon Clark, who would later go on to direct the infamous `Final Justice,' made this. It makes you wonder how the people of Mystery Science Theater 3000 could hammer `Final Justice' and completely miss out on `The Return.'<br /><br />The film is set in a small town in New Mexico. A little boy and girl are in the street unsupervised one night when a powerful flashlight beam.er.a spaceship appears and hovers over them. In probably the worst special effect sequence of the film, the ship spews some kind of red ink on them. It looked like Clark had held a beaker of water in from of the camera lens and dipped his leaky pen in it, so right away you are treated with cheese. Anyhow, the ship leaves and the adults don't believe the children. Elsewhere, we see Vincent Schiavelli, whom I find to be a terrific actor (watch his scenes in `Ghost' for proof, as they are outstanding), who is playing a prospector, or as I called him, the Miner 1949er. He steps out of the cave he is in, and he and his dog are inked by the ship. Twenty-five years go by, and the girl has grown up to be Cybill Shepherd, who works with her father, Raymond Burr, in studying unusual weather phenomena. Or something like that. Shepherd spots some strange phenomena in satellite pictures over that little New Mexico town, and she travels there to research it. Once she gets there, the local ranchers harass her, and blame her for the recent slew of cattle mutilations that have been going on, and deputy Jan-Michael Vincent comes to her rescue. From this point on, the film really drags as the two quickly fall for each other, especially after Vincent wards off the locals and informs Shepherd that he was the little boy that saw the ship with her twenty-five years earlier. While this boring mess is happening, Vincent Schiavelli, with his killer dog at his side, is walking around killing the cattle and any people he runs into with an unusual item. You know those glowing plastic sticks stores sell for trick-or-treaters at Halloween, the kind that you shake to make them glow? Schiavelli uses what looks like one of those glow sticks to burn incisions in people. It's the second-worst effect in the movie. Every time Schiavelli is on screen with the glow stick, the scene's atmosphere suddenly turns dark, like the filmmakers thought the glow stick needed that enhancement. It ends up making the movie look even cheaper than it is.<br /><br />And what does all this lead up to? It's hard to tell when the final, confusing scene arrives. See, Burr and his team of scientists try to explain the satellite images that Shepherd found as some kind of `calling card,' but none of it makes sense. Why do Shepherd and Vincent age and Schiavelli does not? Schiavelli explains why he is killing cattle and people and why he wants Shepherd dead, but even that doesn't make much sense when you really think about it. I mean, why doesn't he kill Jan-Michael Vincent? After all, he had twenty-five years to do it. And the aliens won't need him if Shepherd is dead anyhow, so why try to kill her? Speaking of the aliens, it is never clear what they really wanted out of Shepherd and Vincent. What is their goal? Why do they wait so long to intervene? How could they be so sure Shepherd would come back? Not that the answer to any of these and other questions would have made `The Return' any more pleasant. You would still have bad lines, really bad acting, particularly by Shepherd, cheesy effects, and poor direction. Luckily, the stars escaped from this movie. Cybill Shepherd soon went on to star in `Moonlighting' with Bruce Willis. Jan-Michael Vincent went on to be featured in dozens of B-movies, often in over-the-top parts. Raymond Burr made a pile of Perry Mason television movies right up until his death. Vincent Schiavelli went on to be a great character actor in a huge number of films. Martin Landau, who played a kooky law enforcement officer, quickly made the terrific `Alone in the Dark' and the awful `The Being' before rolling into the films he has been famous for recently. You can bet none of these stars ever want their careers to return to `The Return.' Zantara's score: 2 out of 10.\n",
            "Label: Negative\n"
          ]
        }
      ],
      "source": [
        "review_number = 42\n",
        "review_text = imdb_dataset['train'][review_number]['text']\n",
        "review_label = imdb_dataset['train'][review_number]['label']\n",
        "\n",
        "print(f\"Review text: {review_text}\")\n",
        "print(f\"Label: {'Positive' if review_label == 1 else 'Negative'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE3pfJ0ssH0R"
      },
      "source": [
        "There are a lot of reviews in here!\n",
        "\n",
        "We'll look at number 42 from the train split of the dataset, since 42 is a great number üòâ\n",
        "\n",
        "To access the text of the dataset, we use the key named 'text'.\n",
        "\n",
        "The label is provided as either 0 or 1 and obtained using the 'label' key.\n",
        "\n",
        "Try printing other reviews and their labels. Are they positive or negative?\n",
        "\n",
        "### More ideas:\n",
        "- Count how many positive and negative reviews are in the first 100 samples\n",
        "- Find the longest review in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_v8glw6sH0R"
      },
      "source": [
        "An important feature of the datasets library is its efficiency. Built on top of Apache Arrow, it allows for lightning-fast operations, ensuring that even large datasets can be processed seamlessly without hogging memory resources.\n",
        "\n",
        "### Fun fact:\n",
        "- You can filter, map, and batch process millions of samples quickly!\n",
        "- Try filtering all positive reviews or mapping a function to clean the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amxhUHknsH0R"
      },
      "source": [
        "## üèãÔ∏è‚Äç‚ôÇÔ∏è Trainer\n",
        "\n",
        "HuggingFace also makes training a model easier! The `Trainer` class offers a streamlined solution for training and fine-tuning machine learning models. It encapsulates much of the complexity associated with training loops, evaluation, and optimization.\n",
        "\n",
        "### Why use Trainer?\n",
        "- Handles training, evaluation, and saving models automatically\n",
        "- Supports logging, early stopping, and more\n",
        "- Works with any HuggingFace model and dataset\n",
        "\n",
        "Let's see how to set up a Trainer for a classification task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "3eda4d81beb545698deafd45e00fa5ea",
            "8ff7f193d879487281736c5b5c497277",
            "5b9f1af92c51400ba1b8af9d3cab06fc",
            "1b9149c2fcf54e079427daf1de867840",
            "dd726ba72be841b7b01191cfe57f6396",
            "364a27063c744f548e73be90ac896593",
            "f4204fc177e245a5b4d825153db49f42",
            "c7d254beb4f84c8fa1c972ee1effcbdb",
            "82179129d0144daca4240a9e327e901b",
            "74aa7e1d6cd54028a8f6abca04a6939d",
            "5b959113f8ca480489f43e8dbe7f2787",
            "b278fb3fda1846a5b32200100aa9058a",
            "198023dbcb894b0997f6e952219cd336",
            "b33d7bc8bcc2405eacf14fcfc42fdb27",
            "57e4a2be775f48cab77dcc25ae5bdb13",
            "3c60b273b92e46a386b234681e64d272",
            "e7aa3d21807b478ebb31ab7e3d54626e",
            "1a7034536a4d4d28bb781f281912bc3a",
            "71cb54030c5440d28548e6b5956d3330",
            "438ee659fa0e4925908f038373e63060",
            "66a00a2fce764aa4a1118faf1429ee29",
            "e3ec4c9ed31041a9b35d0b9af6823661"
          ]
        },
        "id": "JO5rCuk2sH0R",
        "outputId": "fb174fe1-dbc0-402b-8447-a39c14191702"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c3e2afec61a4a60b81733cdafd785a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
            "Key                     | Status     | \n",
            "------------------------+------------+-\n",
            "vocab_layer_norm.weight | UNEXPECTED | \n",
            "vocab_projector.bias    | UNEXPECTED | \n",
            "vocab_layer_norm.bias   | UNEXPECTED | \n",
            "vocab_transform.bias    | UNEXPECTED | \n",
            "vocab_transform.weight  | UNEXPECTED | \n",
            "pre_classifier.bias     | MISSING    | \n",
            "pre_classifier.weight   | MISSING    | \n",
            "classifier.bias         | MISSING    | \n",
            "classifier.weight       | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "628816d1ab4141d0bd17d416479b0319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define the pre-trained model name\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Define a function to tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the text, pad to the max length, and truncate\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Load the IMDb dataset\n",
        "imdb_dataset = load_dataset('imdb')\n",
        "\n",
        "# Select a smaller subset of the dataset for faster training\n",
        "subset_size = 1000 # Define the size of the subset\n",
        "small_train_dataset = imdb_dataset[\"train\"].shuffle(seed=42).select(range(subset_size))\n",
        "small_test_dataset = imdb_dataset[\"test\"].shuffle(seed=42).select(range(subset_size))\n",
        "\n",
        "\n",
        "# Apply the tokenization function to the subset datasets\n",
        "tokenized_datasets = {\n",
        "    \"train\": small_train_dataset.map(tokenize_function, batched=True),\n",
        "    \"test\": small_test_dataset.map(tokenize_function, batched=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4YVpxGGsH0R"
      },
      "source": [
        "Let's start by loading the 'distilbert-base-uncased' pre-trained model and its tokenizer.\n",
        "\n",
        "Next, we create a function called `tokenize_function` which takes a review and converts it to tokens that the large language model will understand. Notice that we are truncating long strings and padding shorter ones. We then load the IMDB movie review dataset. For demonstration, we use a subset, but you can train on the whole dataset if you want!\n",
        "\n",
        "Try changing the subset size or using a different dataset for your own experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sZtP0G_0sH0R"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to='none', # Disable reporting to experiment tracking services\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW7xbNMDsH0S"
      },
      "source": [
        "With that all set, we define some training arguments. Here we set the batch size, output directory, learning rate, and number of epochs. We also specify which splits of the dataset to use for training and evaluation.\n",
        "\n",
        "### Try changing:\n",
        "- The learning rate (try 5e-5 or 1e-4)\n",
        "- The number of epochs (try 1 or 5)\n",
        "- The batch size (try 16 or 128)\n",
        "\n",
        "See how these changes affect training speed and model performance!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "zb9THE3FsH0S",
        "outputId": "7ae13116-2bd4-4dfa-c839-41845ebb6021"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    #tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Ju_h-SsH0S"
      },
      "source": [
        "Now we create a `Trainer` object and start training!\n",
        "\n",
        "The Trainer will handle the training loop, evaluation, and even saving the best model for you.\n",
        "\n",
        "### More ideas:\n",
        "- Add evaluation metrics (like accuracy or F1-score)\n",
        "- Save and reload your trained model\n",
        "- Try training on a different dataset or with a different model\n",
        "\n",
        "Congratulations, you just trained a model with HuggingFace! üéâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7a64966"
      },
      "source": [
        "Let‚Äôs start with loading the distilbert-base-uncased pre-trained model as well as the tokenizer it uses.\n",
        "\n",
        "Next we will create a function called tokenize_function which takes a review, and converts it to tokens that the large language model will understand. Notice that we are also truncating long strings as well as padding shorter strings. We then load the IMDB movie review dataset, and **we are using a subset of the dataset for faster training**. We then map this dataset to a new dataset with the tokenized, padded, and truncated reviews."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "198023dbcb894b0997f6e952219cd336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7aa3d21807b478ebb31ab7e3d54626e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1a7034536a4d4d28bb781f281912bc3a",
            "value": "Map:‚Äá100%"
          }
        },
        "1a7034536a4d4d28bb781f281912bc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9149c2fcf54e079427daf1de867840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74aa7e1d6cd54028a8f6abca04a6939d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5b959113f8ca480489f43e8dbe7f2787",
            "value": "‚Äá1000/1000‚Äá[00:02&lt;00:00,‚Äá435.37‚Äáexamples/s]"
          }
        },
        "364a27063c744f548e73be90ac896593": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c60b273b92e46a386b234681e64d272": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eda4d81beb545698deafd45e00fa5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ff7f193d879487281736c5b5c497277",
              "IPY_MODEL_5b9f1af92c51400ba1b8af9d3cab06fc",
              "IPY_MODEL_1b9149c2fcf54e079427daf1de867840"
            ],
            "layout": "IPY_MODEL_dd726ba72be841b7b01191cfe57f6396"
          }
        },
        "438ee659fa0e4925908f038373e63060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57e4a2be775f48cab77dcc25ae5bdb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a00a2fce764aa4a1118faf1429ee29",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e3ec4c9ed31041a9b35d0b9af6823661",
            "value": "‚Äá1000/1000‚Äá[00:01&lt;00:00,‚Äá755.94‚Äáexamples/s]"
          }
        },
        "5b959113f8ca480489f43e8dbe7f2787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b9f1af92c51400ba1b8af9d3cab06fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d254beb4f84c8fa1c972ee1effcbdb",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82179129d0144daca4240a9e327e901b",
            "value": 1000
          }
        },
        "66a00a2fce764aa4a1118faf1429ee29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71cb54030c5440d28548e6b5956d3330": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74aa7e1d6cd54028a8f6abca04a6939d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82179129d0144daca4240a9e327e901b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ff7f193d879487281736c5b5c497277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364a27063c744f548e73be90ac896593",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f4204fc177e245a5b4d825153db49f42",
            "value": "Map:‚Äá100%"
          }
        },
        "b278fb3fda1846a5b32200100aa9058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_198023dbcb894b0997f6e952219cd336",
              "IPY_MODEL_b33d7bc8bcc2405eacf14fcfc42fdb27",
              "IPY_MODEL_57e4a2be775f48cab77dcc25ae5bdb13"
            ],
            "layout": "IPY_MODEL_3c60b273b92e46a386b234681e64d272"
          }
        },
        "b33d7bc8bcc2405eacf14fcfc42fdb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71cb54030c5440d28548e6b5956d3330",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_438ee659fa0e4925908f038373e63060",
            "value": 1000
          }
        },
        "c7d254beb4f84c8fa1c972ee1effcbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd726ba72be841b7b01191cfe57f6396": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ec4c9ed31041a9b35d0b9af6823661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7aa3d21807b478ebb31ab7e3d54626e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4204fc177e245a5b4d825153db49f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
